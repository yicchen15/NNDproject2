{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 50\n",
    "mypath = \"./Training\"\n",
    "size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13627027981035449527\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1401988300\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 272300220540969152\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices()) #確認有抓到GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.__version__ is 2.1.0\n",
      "tf.keras.__version__ is: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "\n",
    "print(\"tf.__version__ is\", tf.__version__)\n",
    "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
    "\n",
    "def _get_available_gpus():\n",
    "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
    "\n",
    "    # Returns\n",
    "        A list of available GPU devices.\n",
    "    \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "    if tfback._LOCAL_DEVICES is None:\n",
    "        devices = tf.config.list_logical_devices()\n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "\n",
    "tfback._get_available_gpus = _get_available_gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練集 img&label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 增加訓練集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_train = ImageDataGenerator(\n",
    "    rescale=1./255,               # 從0~255整數，壓縮為0~1浮點數\n",
    "    rotation_range=35,            # 隨機旋轉 ±45°\n",
    "    width_shift_range=.15,        # 隨機水平移動 ±15%\n",
    "    height_shift_range=.15,       # 隨機垂直移動 ±15%\n",
    "    horizontal_flip=True,         # 隨機水平翻轉\n",
    "    zoom_range=0.3                # 隨機縮放 50%\n",
    ")\n",
    "#image_gen_train.flow(img_tra,y_t,batch_size=64)\n",
    "\n",
    "from PIL import Image\n",
    "import keras\n",
    "df_t = pd.read_excel(\"./Training-label.xlsx\",header=None)  \n",
    "k=180\n",
    "for j in range(180):\n",
    "    y_origin = df_t.loc[j,0]\n",
    "    if j < 9:\n",
    "         file_name = './Training/00'+str(j+1)+'.jpg'\n",
    "    elif j < 99:\n",
    "        file_name = './Training/0'+str(j+1)+'.jpg'\n",
    "    else :\n",
    "        file_name = './Training/'+str(j+1)+'.jpg'\n",
    "    #print(file_name)\n",
    "    img = cv2.imread(file_name)  \n",
    "    img = cv2.resize(img, (size,size))##改變圖片尺寸\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #Cv2讀進來是BGR，轉成RGB\n",
    "    img_origin=img.copy()\n",
    "    img= np.array(img, dtype=np.float32)\n",
    "    img_combine=np.array([img,img,img,img],dtype=np.float32) ##輸入generator要是四維\n",
    "    batch_gen = image_gen_train.flow(img_combine, batch_size=4)\n",
    "    assert next(batch_gen).shape==(4, size, size, 3)\n",
    "    \n",
    "    for i,batch in enumerate(batch_gen):\n",
    "        k=k+1\n",
    "        if i>4 : break\n",
    "        im_new = batch[0]\n",
    "        #im_new  = np.array(im_new)\n",
    "        #print(im_new.shape)\n",
    "        im_new = keras.preprocessing.image.array_to_img(im_new)\n",
    "        #im_new=Image.fromarray(im_new) # numpy轉image类\n",
    "        im_new.save('./Training/'+str(k)+'.jpg') #顯示圖片\n",
    "        #cv2.imwrite('./Training/'+str(200+i)+'.jpg',im_new)\n",
    "        df_t = df_t.append([y_origin],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 訓練圖片組合成矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 128, 128, 3)\n",
      "(1080, 18)\n"
     ]
    }
   ],
   "source": [
    "##將cvs裡面答案轉為陣列\n",
    "#df_t = df_t.T\n",
    "df_temp = pd.get_dummies(df_t[0]) #One-hot編碼\n",
    "y_t = np.array(df_temp)\n",
    "#print(y_t)\n",
    "##將驗證圖片讀檔，二值化並存成2維陣列180*(4096)\n",
    "size = 128\n",
    "img_tra = []\n",
    "\n",
    "# 指定要列出所有檔案的目錄\n",
    "mypath = \"./Training\"\n",
    "# 取得所有檔案與子目錄名稱\n",
    "files = listdir(mypath)\n",
    "# 以迴圈處理\n",
    "for i,f in enumerate(files):\n",
    "    # 產生檔案的絕對路徑\n",
    "    fullpath = join(mypath, f)\n",
    "    #print(f)\n",
    "    # 判斷 fullpath 是檔案還是目錄\n",
    "    ro = False\n",
    "    if isfile(fullpath):\n",
    "        im = cv2.resize(cv2.imread(fullpath,0),(size,size))\n",
    "        image = cv2.resize(cv2.imread(fullpath),(size,size))\n",
    "        image_array=np.array(image/255,dtype='float32')\n",
    "        img_tra.append(image_array)\n",
    "img_tra = np.array(img_tra)\n",
    "print(img_tra.shape)\n",
    "print(y_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 驗證/測試集img&label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 128, 128, 3)\n",
      "(50, 18)\n"
     ]
    }
   ],
   "source": [
    "##將cvs裡面答案轉為陣列\n",
    "df_v = pd.read_excel('./Validation-label.xlsx',header=None)  \n",
    "#print(df_v)\n",
    "#df_v = df_v.T\n",
    "df_v_temp = pd.get_dummies(df_v[0]) #One-hot編碼\n",
    "y_v = np.array(df_v_temp)\n",
    "\n",
    "img_val = []#np.zeros((50,size*size,3))\n",
    "# 指定要列出所有檔案的目錄\n",
    "mypath = \"./Validation\"\n",
    "# 取得所有檔案與子目錄名稱\n",
    "files = listdir(mypath)\n",
    "for i,f in enumerate(files):\n",
    "    # 產生檔案的絕對路徑\n",
    "    fullpath = join(mypath, f)\n",
    "    #print(f)\n",
    "    # 判斷 fullpath 是檔案還是目錄\n",
    "    ro = False\n",
    "    if isfile(fullpath):\n",
    "        im = cv2.resize(cv2.imread(fullpath,0),(size,size))\n",
    "        image = cv2.resize(cv2.imread(fullpath),(size,size))\n",
    "        img_val.append(image/255)\n",
    "img_val = np.array(img_val)\n",
    "print(img_val.shape)\n",
    "print(y_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8388736   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 18)                2322      \n",
      "=================================================================\n",
      "Total params: 8,444,754\n",
      "Trainable params: 8,444,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1080 samples, validate on 50 samples\n",
      "Epoch 1/30\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 3.5162 - accuracy: 0.0611 - val_loss: 2.8903 - val_accuracy: 0.0600\n",
      "Epoch 2/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 2.8904 - accuracy: 0.0519 - val_loss: 2.8913 - val_accuracy: 0.0600\n",
      "Epoch 3/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 2.8904 - accuracy: 0.0704 - val_loss: 2.8861 - val_accuracy: 0.0600\n",
      "Epoch 4/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 2.8855 - accuracy: 0.0778 - val_loss: 2.8667 - val_accuracy: 0.1400\n",
      "Epoch 5/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 2.8606 - accuracy: 0.0889 - val_loss: 2.8105 - val_accuracy: 0.2000\n",
      "Epoch 6/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 2.7984 - accuracy: 0.1546 - val_loss: 2.7847 - val_accuracy: 0.1200\n",
      "Epoch 7/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 2.6640 - accuracy: 0.2009 - val_loss: 2.6814 - val_accuracy: 0.2800\n",
      "Epoch 8/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 2.4836 - accuracy: 0.2750 - val_loss: 2.8137 - val_accuracy: 0.1600\n",
      "Epoch 9/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 2.2311 - accuracy: 0.3259 - val_loss: 2.7545 - val_accuracy: 0.2200\n",
      "Epoch 10/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.8714 - accuracy: 0.4352 - val_loss: 2.9529 - val_accuracy: 0.2000\n",
      "Epoch 11/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.5450 - accuracy: 0.5481 - val_loss: 3.0434 - val_accuracy: 0.2200\n",
      "Epoch 12/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.2223 - accuracy: 0.6528 - val_loss: 3.1490 - val_accuracy: 0.1200\n",
      "Epoch 13/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.9282 - accuracy: 0.7361 - val_loss: 3.8659 - val_accuracy: 0.1200\n",
      "Epoch 14/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.7187 - accuracy: 0.8130 - val_loss: 4.5346 - val_accuracy: 0.0800\n",
      "Epoch 15/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.5069 - accuracy: 0.8731 - val_loss: 4.2368 - val_accuracy: 0.0800\n",
      "Epoch 16/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.3739 - accuracy: 0.9083 - val_loss: 4.9529 - val_accuracy: 0.1000\n",
      "Epoch 17/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.2640 - accuracy: 0.9287 - val_loss: 5.1864 - val_accuracy: 0.1000\n",
      "Epoch 18/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.2030 - accuracy: 0.9602 - val_loss: 5.3024 - val_accuracy: 0.1000\n",
      "Epoch 19/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.1605 - accuracy: 0.9722 - val_loss: 5.7747 - val_accuracy: 0.1200\n",
      "Epoch 20/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.1506 - accuracy: 0.9667 - val_loss: 5.7830 - val_accuracy: 0.1200\n",
      "Epoch 21/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.0985 - accuracy: 0.9796 - val_loss: 6.2793 - val_accuracy: 0.1000\n",
      "Epoch 22/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.9796 - val_loss: 6.8143 - val_accuracy: 0.1600\n",
      "Epoch 23/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.0554 - accuracy: 0.9880 - val_loss: 6.7658 - val_accuracy: 0.1600\n",
      "Epoch 24/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.0632 - accuracy: 0.9833 - val_loss: 6.5326 - val_accuracy: 0.1600\n",
      "Epoch 25/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.0544 - accuracy: 0.9880 - val_loss: 6.5499 - val_accuracy: 0.0800\n",
      "Epoch 26/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.0443 - accuracy: 0.9926 - val_loss: 7.3116 - val_accuracy: 0.1200\n",
      "Epoch 27/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.0329 - accuracy: 0.9963 - val_loss: 7.4919 - val_accuracy: 0.0600\n",
      "Epoch 28/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.0294 - accuracy: 0.9944 - val_loss: 7.3250 - val_accuracy: 0.1600\n",
      "Epoch 29/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.0241 - accuracy: 0.9963 - val_loss: 7.1827 - val_accuracy: 0.1400\n",
      "Epoch 30/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.0261 - accuracy: 0.9954 - val_loss: 7.5923 - val_accuracy: 0.1200\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "img_pix=size\n",
    "#建立一個線性堆疊的模型\n",
    "model = Sequential()\n",
    "#建立卷積層1\n",
    "model.add(Conv2D(filters=32,kernel_size=(5,5),padding='same',input_shape=(img_pix,img_pix,3),activation='relu'))\n",
    "#建立池化層1。\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#建立卷積層2\n",
    "model.add(Conv2D(filters=64,kernel_size=(5,5),padding='same',activation='relu'))\n",
    "#建立池化層2\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#避免overfitting\n",
    "model.add(Dropout(0.25))\n",
    "#建立平滑層\n",
    "model.add(Flatten())\n",
    "#建立隱藏層，且避免overfitting\n",
    "model.add(Dense(img_pix,activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "#建立輸出層\n",
    "model.add(Dense(18,activation='softmax'))\n",
    "#設定損失函數，最佳化方法，以及評估模型等。\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "##開始訓練\n",
    "train_history=model.fit(x=img_tra ,y=y_t,validation_data=(img_val,y_v),\\\n",
    "                        epochs=30,batch_size=150,verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
